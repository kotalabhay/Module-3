{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Word2Vec Model using Skip-Gram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Necesssary Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import string \n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/Skip-gram-architecture-2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some variables :\n",
    "\n",
    "V    Number of unique words in our corpus of text ( Vocabulary )<br>\n",
    "x    Input layer (One hot encoding of our input word ). <br>\n",
    "N    Number of neurons in the hidden layer of neural network<br>\n",
    "W    Weights between input layer and hidden layer<br>\n",
    "W'   Weights between hidden layer and output layer<br>\n",
    "y    A softmax output layer having probabilities of every word in our vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def softmax(x): \n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x)) \n",
    "    return e_x / e_x.sum() \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contains Functions for Forward Propogation, Backward Propogation, Training and Predicting the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In <b>Forward Propogation</b>, We multiply one hot encoding of centre word (denoted by x) with the first weight matrix W to get hidden layer matrix h (of size N x 1). We then multiply the hidden layer vector h with second weight matrix W’ to get a new matrix u. We Then obtain our loss function, Which comes out to be <br><img src=\"https://miro.medium.com/max/994/1*XPhzBnf1xEb0u67qazx9nA.png\"><br>\n",
    "E being our Loss Function.<br>\n",
    "In <b>Backward Propogation</b>, We find the partial derivatives of our loss function with respect to W and W’ to apply gradient descent algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2vec(object): \n",
    "    def __init__(self): \n",
    "        self.N = 10\n",
    "        self.X_train = [] \n",
    "        self.y_train = [] \n",
    "        self.window_size = 2\n",
    "        self.alpha = 0.001\n",
    "        self.words = [] \n",
    "        self.word_index = {} \n",
    "   \n",
    "    def initialize(self,V,data): \n",
    "        self.V = V \n",
    "        self.W = np.random.uniform(-0.8, 0.8, (self.V, self.N)) \n",
    "        self.W1 = np.random.uniform(-0.8, 0.8, (self.N, self.V)) \n",
    "           \n",
    "        self.words = data \n",
    "        for i in range(len(data)): \n",
    "            self.word_index[data[i]] = i \n",
    "   \n",
    "       \n",
    "    def feed_forward(self,X): \n",
    "        self.h = np.dot(self.W.T,X).reshape(self.N,1) \n",
    "        self.u = np.dot(self.W1.T,self.h) \n",
    "        #print(self.u) \n",
    "        self.y = softmax(self.u)   \n",
    "        return self.y \n",
    "           \n",
    "    def backpropagate(self,x,t): \n",
    "        e = self.y - np.asarray(t).reshape(self.V,1) \n",
    "        # e.shape is V x 1 \n",
    "        dLdW1 = np.dot(self.h,e.T) \n",
    "        X = np.array(x).reshape(self.V,1) \n",
    "        dLdW = np.dot(X, np.dot(self.W1,e).T) \n",
    "        self.W1 = self.W1 - self.alpha*dLdW1 \n",
    "        self.W = self.W - self.alpha*dLdW \n",
    "           \n",
    "    def train(self,epochs): \n",
    "        for x in range(1,epochs):         \n",
    "            self.loss = 0\n",
    "            for j in range(len(self.X_train)): \n",
    "                self.feed_forward(self.X_train[j]) \n",
    "                self.backpropagate(self.X_train[j],self.y_train[j]) \n",
    "                C = 0\n",
    "                for m in range(self.V): \n",
    "                    if(self.y_train[j][m]): \n",
    "                        self.loss += -1*self.u[m][0] \n",
    "                        C += 1\n",
    "                self.loss += C*np.log(np.sum(np.exp(self.u))) \n",
    "            print(\"epoch \",x, \" loss = \",self.loss) \n",
    "            self.alpha *= 1/( (1+self.alpha*x) ) \n",
    "              \n",
    "    def predict(self,word,number_of_predictions): \n",
    "        if word in self.words: \n",
    "            index = self.word_index[word] \n",
    "            X = [0 for i in range(self.V)] \n",
    "            X[index] = 1\n",
    "            prediction = self.feed_forward(X) \n",
    "            output = {} \n",
    "            for i in range(self.V): \n",
    "                output[prediction[i][0]] = i \n",
    "               \n",
    "            top_context_words = [] \n",
    "            for k in sorted(output,reverse=True): \n",
    "                top_context_words.append(self.words[output[k]]) \n",
    "                if(len(top_context_words)>=number_of_predictions): \n",
    "                    break\n",
    "       \n",
    "            return top_context_words \n",
    "        else: \n",
    "            print(\"Word not found in dicitonary\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Preparing and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(corpus): \n",
    "    stop_words = set(stopwords.words('english'))     \n",
    "    training_data = [] \n",
    "    sentences = corpus.split(\".\") \n",
    "    for i in range(len(sentences)): \n",
    "        sentences[i] = sentences[i].strip() \n",
    "        sentence = sentences[i].split() \n",
    "        x = [word.strip(string.punctuation) for word in sentence \n",
    "                                     if word not in stop_words] \n",
    "        x = [word.lower() for word in x] \n",
    "        training_data.append(x) \n",
    "    return training_data \n",
    "       \n",
    "   \n",
    "def prepare_data_for_training(sentences,w2v): \n",
    "    data = {} \n",
    "    for sentence in sentences: \n",
    "        for word in sentence: \n",
    "            if word not in data: \n",
    "                data[word] = 1\n",
    "            else: \n",
    "                data[word] += 1\n",
    "    V = len(data) \n",
    "    data = sorted(list(data.keys())) \n",
    "    vocab = {} \n",
    "    for i in range(len(data)): \n",
    "        vocab[data[i]] = i \n",
    "       \n",
    "    #for i in range(len(words)): \n",
    "    for sentence in sentences: \n",
    "        for i in range(len(sentence)): \n",
    "            center_word = [0 for x in range(V)] \n",
    "            center_word[vocab[sentence[i]]] = 1\n",
    "            context = [0 for x in range(V)] \n",
    "              \n",
    "            for j in range(i-w2v.window_size,i+w2v.window_size): \n",
    "                if i!=j and j>=0 and j<len(sentence): \n",
    "                    context[vocab[sentence[j]]] += 1\n",
    "            w2v.X_train.append(center_word) \n",
    "            w2v.y_train.append(context) \n",
    "    w2v.initialize(V,data) \n",
    "   \n",
    "    return w2v.X_train,w2v.y_train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  loss =  155.32711193049806\n",
      "epoch  2  loss =  155.1349316035461\n",
      "epoch  3  loss =  154.94353942346672\n",
      "epoch  4  loss =  154.7531178148475\n",
      "epoch  5  loss =  154.56384470573835\n",
      "epoch  6  loss =  154.37589254337567\n",
      "epoch  7  loss =  154.18942738072514\n",
      "epoch  8  loss =  154.00460804544744\n",
      "epoch  9  loss =  153.82158540087147\n",
      "epoch  10  loss =  153.64050170636978\n",
      "epoch  11  loss =  153.46149008222966\n",
      "epoch  12  loss =  153.28467408181294\n",
      "epoch  13  loss =  153.11016737154267\n",
      "epoch  14  loss =  152.93807351715242\n",
      "epoch  15  loss =  152.7684858727068\n",
      "epoch  16  loss =  152.60148756722347\n",
      "epoch  17  loss =  152.4371515823133\n",
      "epoch  18  loss =  152.27554091313297\n",
      "epoch  19  loss =  152.11670880411143\n",
      "epoch  20  loss =  151.96069905037015\n",
      "epoch  21  loss =  151.80754635547663\n",
      "epoch  22  loss =  151.65727673614865\n",
      "epoch  23  loss =  151.50990796470336\n",
      "epoch  24  loss =  151.36545004041778\n",
      "epoch  25  loss =  151.22390568147884\n",
      "epoch  26  loss =  151.08527082982565\n",
      "epoch  27  loss =  150.94953516189227\n",
      "epoch  28  loss =  150.8166825990129\n",
      "epoch  29  loss =  150.6866918120241\n",
      "epoch  30  loss =  150.55953671537551\n",
      "epoch  31  loss =  150.43518694681168\n",
      "epoch  32  loss =  150.3136083294073\n",
      "epoch  33  loss =  150.19476331340718\n",
      "epoch  34  loss =  150.07861139594237\n",
      "epoch  35  loss =  149.96510951724719\n",
      "epoch  36  loss =  149.85421243250028\n",
      "epoch  37  loss =  149.74587305884302\n",
      "epoch  38  loss =  149.6400427975036\n",
      "epoch  39  loss =  149.5366718312666\n",
      "epoch  40  loss =  149.43570939779312\n",
      "epoch  41  loss =  149.33710403950224\n",
      "epoch  42  loss =  149.24080383089392\n",
      "epoch  43  loss =  149.146756584319\n",
      "epoch  44  loss =  149.05491003529255\n",
      "epoch  45  loss =  148.96521200850526\n",
      "epoch  46  loss =  148.8776105657262\n",
      "epoch  47  loss =  148.79205413679833\n",
      "epoch  48  loss =  148.70849163492477\n",
      "epoch  49  loss =  148.62687255742355\n",
      "epoch  50  loss =  148.5471470730951\n",
      "epoch  51  loss =  148.46926609730707\n",
      "epoch  52  loss =  148.3931813558526\n",
      "epoch  53  loss =  148.31884543858487\n",
      "epoch  54  loss =  148.24621184377705\n",
      "epoch  55  loss =  148.17523501409616\n",
      "epoch  56  loss =  148.10587036502503\n",
      "epoch  57  loss =  148.03807430650485\n",
      "epoch  58  loss =  147.9718042585182\n",
      "epoch  59  loss =  147.90701866127333\n",
      "epoch  60  loss =  147.84367698060157\n",
      "epoch  61  loss =  147.78173970912562\n",
      "epoch  62  loss =  147.72116836371077\n",
      "epoch  63  loss =  147.66192547966605\n",
      "epoch  64  loss =  147.60397460211635\n",
      "epoch  65  loss =  147.54728027493337\n",
      "epoch  66  loss =  147.4918080275694\n",
      "epoch  67  loss =  147.43752436010837\n",
      "epoch  68  loss =  147.38439672681648\n",
      "epoch  69  loss =  147.33239351844273\n",
      "epoch  70  loss =  147.28148404349793\n",
      "epoch  71  loss =  147.2316385087111\n",
      "epoch  72  loss =  147.18282799884457\n",
      "epoch  73  loss =  147.13502445602563\n",
      "epoch  74  loss =  147.08820065873556\n",
      "epoch  75  loss =  147.04233020057933\n",
      "epoch  76  loss =  146.99738746894602\n",
      "epoch  77  loss =  146.95334762365331\n",
      "epoch  78  loss =  146.9101865756599\n",
      "epoch  79  loss =  146.86788096591687\n",
      "epoch  80  loss =  146.8264081444205\n",
      "epoch  81  loss =  146.785746149518\n",
      "epoch  82  loss =  146.74587368751224\n",
      "epoch  83  loss =  146.70677011260258\n",
      "epoch  84  loss =  146.66841540719315\n",
      "epoch  85  loss =  146.63079016259468\n",
      "epoch  86  loss =  146.5938755601396\n",
      "epoch  87  loss =  146.55765335272847\n",
      "epoch  88  loss =  146.52210584681887\n",
      "epoch  89  loss =  146.4872158848651\n",
      "epoch  90  loss =  146.4529668282174\n",
      "epoch  91  loss =  146.4193425404803\n",
      "epoch  92  loss =  146.38632737133517\n",
      "epoch  93  loss =  146.35390614082192\n",
      "epoch  94  loss =  146.32206412408104\n",
      "epoch  95  loss =  146.29078703654926\n",
      "epoch  96  loss =  146.26006101960428\n",
      "epoch  97  loss =  146.22987262665302\n",
      "epoch  98  loss =  146.2002088096538\n",
      "epoch  99  loss =  146.1710569060678\n",
      "epoch  100  loss =  146.14240462622712\n",
      "epoch  101  loss =  146.1142400411138\n",
      "epoch  102  loss =  146.0865515705384\n",
      "epoch  103  loss =  146.05932797170797\n",
      "epoch  104  loss =  146.03255832817524\n",
      "epoch  105  loss =  146.00623203915694\n",
      "epoch  106  loss =  145.9803388092117\n",
      "epoch  107  loss =  145.95486863826784\n",
      "epoch  108  loss =  145.9298118119894\n",
      "epoch  109  loss =  145.90515889247183\n",
      "epoch  110  loss =  145.88090070925554\n",
      "epoch  111  loss =  145.85702835064913\n",
      "epoch  112  loss =  145.83353315535027\n",
      "epoch  113  loss =  145.81040670435684\n",
      "epoch  114  loss =  145.78764081315745\n",
      "epoch  115  loss =  145.7652275241921\n",
      "epoch  116  loss =  145.74315909957377\n",
      "epoch  117  loss =  145.7214280140638\n",
      "epoch  118  loss =  145.7000269482896\n",
      "epoch  119  loss =  145.67894878219857\n",
      "epoch  120  loss =  145.6581865887384\n",
      "epoch  121  loss =  145.63773362775783\n",
      "epoch  122  loss =  145.61758334011787\n",
      "epoch  123  loss =  145.5977293420073\n",
      "epoch  124  loss =  145.57816541945525\n",
      "epoch  125  loss =  145.55888552303296\n",
      "epoch  126  loss =  145.53988376273946\n",
      "epoch  127  loss =  145.52115440306255\n",
      "epoch  128  loss =  145.50269185821043\n",
      "epoch  129  loss =  145.48449068750742\n",
      "epoch  130  loss =  145.46654559094688\n",
      "epoch  131  loss =  145.44885140489745\n",
      "epoch  132  loss =  145.43140309795535\n",
      "epoch  133  loss =  145.4141957669377\n",
      "epoch  134  loss =  145.39722463301345\n",
      "epoch  135  loss =  145.38048503796452\n",
      "epoch  136  loss =  145.36397244057363\n",
      "epoch  137  loss =  145.34768241313475\n",
      "epoch  138  loss =  145.3316106380803\n",
      "epoch  139  loss =  145.3157529047222\n",
      "epoch  140  loss =  145.30010510610194\n",
      "epoch  141  loss =  145.28466323594523\n",
      "epoch  142  loss =  145.26942338571928\n",
      "epoch  143  loss =  145.2543817417869\n",
      "epoch  144  loss =  145.23953458265441\n",
      "epoch  145  loss =  145.22487827631227\n",
      "epoch  146  loss =  145.2104092776604\n",
      "epoch  147  loss =  145.1961241260204\n",
      "epoch  148  loss =  145.18201944272766\n",
      "epoch  149  loss =  145.16809192880243\n",
      "epoch  150  loss =  145.1543383626964\n",
      "epoch  151  loss =  145.14075559811258\n",
      "epoch  152  loss =  145.12734056189413\n",
      "epoch  153  loss =  145.11409025198333\n",
      "epoch  154  loss =  145.10100173544367\n",
      "epoch  155  loss =  145.08807214654632\n",
      "epoch  156  loss =  145.0752986849174\n",
      "epoch  157  loss =  145.0626786137434\n",
      "epoch  158  loss =  145.05020925803382\n",
      "epoch  159  loss =  145.0378880029382\n",
      "epoch  160  loss =  145.02571229211622\n",
      "epoch  161  loss =  145.01367962615805\n",
      "epoch  162  loss =  145.00178756105467\n",
      "epoch  163  loss =  144.99003370671528\n",
      "epoch  164  loss =  144.97841572553045\n",
      "epoch  165  loss =  144.9669313309793\n",
      "epoch  166  loss =  144.95557828628048\n",
      "epoch  167  loss =  144.9443544030824\n",
      "epoch  168  loss =  144.93325754019554\n",
      "epoch  169  loss =  144.92228560236177\n",
      "epoch  170  loss =  144.91143653906119\n",
      "epoch  171  loss =  144.90070834335506\n",
      "epoch  172  loss =  144.8900990507632\n",
      "epoch  173  loss =  144.8796067381757\n",
      "epoch  174  loss =  144.86922952279514\n",
      "epoch  175  loss =  144.8589655611127\n",
      "epoch  176  loss =  144.84881304791256\n",
      "epoch  177  loss =  144.83877021530623\n",
      "epoch  178  loss =  144.82883533179577\n",
      "epoch  179  loss =  144.8190067013632\n",
      "epoch  180  loss =  144.80928266258724\n",
      "epoch  181  loss =  144.7996615877859\n",
      "epoch  182  loss =  144.7901418821826\n",
      "epoch  183  loss =  144.78072198309764\n",
      "epoch  184  loss =  144.7714003591621\n",
      "epoch  185  loss =  144.76217550955383\n",
      "epoch  186  loss =  144.75304596325662\n",
      "epoch  187  loss =  144.74401027833827\n",
      "epoch  188  loss =  144.7350670412512\n",
      "epoch  189  loss =  144.72621486615097\n",
      "epoch  190  loss =  144.7174523942348\n",
      "epoch  191  loss =  144.70877829309813\n",
      "epoch  192  loss =  144.70019125610972\n",
      "epoch  193  loss =  144.69169000180324\n",
      "epoch  194  loss =  144.68327327328595\n",
      "epoch  195  loss =  144.67493983766394\n",
      "epoch  196  loss =  144.66668848548233\n",
      "epoch  197  loss =  144.6585180301821\n",
      "epoch  198  loss =  144.65042730756994\n",
      "epoch  199  loss =  144.64241517530348\n",
      "epoch  200  loss =  144.63448051239078\n",
      "epoch  201  loss =  144.6266222187021\n",
      "epoch  202  loss =  144.61883921449575\n",
      "epoch  203  loss =  144.6111304399557\n",
      "epoch  204  loss =  144.60349485474256\n",
      "epoch  205  loss =  144.59593143755552\n",
      "epoch  206  loss =  144.58843918570602\n",
      "epoch  207  loss =  144.5810171147028\n",
      "epoch  208  loss =  144.5736642578481\n",
      "epoch  209  loss =  144.56637966584353\n",
      "epoch  210  loss =  144.5591624064069\n",
      "epoch  211  loss =  144.55201156389882\n",
      "epoch  212  loss =  144.54492623895874\n",
      "epoch  213  loss =  144.53790554815032\n",
      "epoch  214  loss =  144.53094862361624\n",
      "epoch  215  loss =  144.5240546127413\n",
      "epoch  216  loss =  144.5172226778245\n",
      "epoch  217  loss =  144.5104519957594\n",
      "epoch  218  loss =  144.503741757722\n",
      "epoch  219  loss =  144.49709116886703\n",
      "epoch  220  loss =  144.49049944803187\n",
      "epoch  221  loss =  144.48396582744726\n",
      "epoch  222  loss =  144.4774895524558\n",
      "epoch  223  loss =  144.47106988123738\n",
      "epoch  224  loss =  144.46470608454055\n",
      "epoch  225  loss =  144.45839744542218\n",
      "epoch  226  loss =  144.45214325899133\n",
      "epoch  227  loss =  144.44594283216108\n",
      "epoch  228  loss =  144.4397954834062\n",
      "epoch  229  loss =  144.43370054252523\n",
      "epoch  230  loss =  144.42765735041033\n",
      "epoch  231  loss =  144.42166525882126\n",
      "epoch  232  loss =  144.41572363016536\n",
      "epoch  233  loss =  144.40983183728255\n",
      "epoch  234  loss =  144.40398926323562\n",
      "epoch  235  loss =  144.39819530110526\n",
      "epoch  236  loss =  144.39244935379054\n",
      "epoch  237  loss =  144.3867508338128\n",
      "epoch  238  loss =  144.38109916312595\n",
      "epoch  239  loss =  144.37549377292947\n",
      "epoch  240  loss =  144.3699341034869\n",
      "epoch  241  loss =  144.3644196039481\n",
      "epoch  242  loss =  144.35894973217552\n",
      "epoch  243  loss =  144.35352395457505\n",
      "epoch  244  loss =  144.34814174592995\n",
      "epoch  245  loss =  144.342802589239\n",
      "epoch  246  loss =  144.33750597555883\n",
      "epoch  247  loss =  144.33225140384855\n",
      "epoch  248  loss =  144.3270383808194\n",
      "epoch  249  loss =  144.32186642078673\n",
      "epoch  250  loss =  144.3167350455255\n",
      "epoch  251  loss =  144.31164378412967\n",
      "epoch  252  loss =  144.30659217287385\n",
      "epoch  253  loss =  144.30157975507836\n",
      "epoch  254  loss =  144.2966060809779\n",
      "epoch  255  loss =  144.29167070759195\n",
      "epoch  256  loss =  144.286773198599\n",
      "epoch  257  loss =  144.28191312421302\n",
      "epoch  258  loss =  144.27709006106303\n",
      "epoch  259  loss =  144.2723035920749\n",
      "epoch  260  loss =  144.26755330635606\n",
      "epoch  261  loss =  144.26283879908254\n",
      "epoch  262  loss =  144.25815967138803\n",
      "epoch  263  loss =  144.25351553025655\n",
      "epoch  264  loss =  144.24890598841614\n",
      "epoch  265  loss =  144.24433066423524\n",
      "epoch  266  loss =  144.23978918162175\n",
      "epoch  267  loss =  144.23528116992364\n",
      "epoch  268  loss =  144.2308062638318\n",
      "epoch  269  loss =  144.2263641032852\n",
      "epoch  270  loss =  144.22195433337774\n",
      "epoch  271  loss =  144.21757660426746\n",
      "epoch  272  loss =  144.21323057108683\n",
      "epoch  273  loss =  144.20891589385602\n",
      "epoch  274  loss =  144.20463223739705\n",
      "epoch  275  loss =  144.20037927125023\n",
      "epoch  276  loss =  144.19615666959234\n",
      "epoch  277  loss =  144.1919641111558\n",
      "epoch  278  loss =  144.18780127915062\n",
      "epoch  279  loss =  144.18366786118696\n",
      "epoch  280  loss =  144.17956354919963\n",
      "epoch  281  loss =  144.17548803937493\n",
      "epoch  282  loss =  144.17144103207664\n",
      "epoch  283  loss =  144.16742223177692\n",
      "epoch  284  loss =  144.1634313469853\n",
      "epoch  285  loss =  144.15946809018124\n",
      "epoch  286  loss =  144.1555321777472\n",
      "epoch  287  loss =  144.1516233299029\n",
      "epoch  288  loss =  144.14774127064203\n",
      "epoch  289  loss =  144.14388572766796\n",
      "epoch  290  loss =  144.14005643233347\n",
      "epoch  291  loss =  144.1362531195797\n",
      "epoch  292  loss =  144.1324755278768\n",
      "epoch  293  loss =  144.1287233991661\n",
      "epoch  294  loss =  144.12499647880307\n",
      "epoch  295  loss =  144.1212945155016\n",
      "epoch  296  loss =  144.117617261279\n",
      "epoch  297  loss =  144.11396447140274\n",
      "epoch  298  loss =  144.110335904337\n",
      "epoch  299  loss =  144.1067313216922\n",
      "epoch  300  loss =  144.10315048817327\n",
      "epoch  301  loss =  144.09959317153016\n",
      "epoch  302  loss =  144.09605914251\n",
      "epoch  303  loss =  144.09254817480814\n",
      "epoch  304  loss =  144.0890600450216\n",
      "epoch  305  loss =  144.08559453260344\n",
      "epoch  306  loss =  144.0821514198173\n",
      "epoch  307  loss =  144.07873049169297\n",
      "epoch  308  loss =  144.075331535983\n",
      "epoch  309  loss =  144.0719543431204\n",
      "epoch  310  loss =  144.068598706176\n",
      "epoch  311  loss =  144.06526442081824\n",
      "epoch  312  loss =  144.0619512852721\n",
      "epoch  313  loss =  144.05865910027998\n",
      "epoch  314  loss =  144.05538766906253\n",
      "epoch  315  loss =  144.0521367972807\n",
      "epoch  316  loss =  144.0489062929982\n",
      "epoch  317  loss =  144.04569596664481\n",
      "epoch  318  loss =  144.04250563098026\n",
      "epoch  319  loss =  144.0393351010584\n",
      "epoch  320  loss =  144.03618419419317\n",
      "epoch  321  loss =  144.03305272992364\n",
      "epoch  322  loss =  144.02994052998105\n",
      "epoch  323  loss =  144.02684741825544\n",
      "epoch  324  loss =  144.02377322076347\n",
      "epoch  325  loss =  144.02071776561652\n",
      "epoch  326  loss =  144.01768088298968\n",
      "epoch  327  loss =  144.0146624050906\n",
      "epoch  328  loss =  144.0116621661299\n",
      "epoch  329  loss =  144.00868000229133\n",
      "epoch  330  loss =  144.00571575170244\n",
      "epoch  331  loss =  144.00276925440645\n",
      "epoch  332  loss =  143.9998403523341\n",
      "epoch  333  loss =  143.99692888927547\n",
      "epoch  334  loss =  143.99403471085395\n",
      "epoch  335  loss =  143.99115766449822\n",
      "epoch  336  loss =  143.98829759941762\n",
      "epoch  337  loss =  143.98545436657517\n",
      "epoch  338  loss =  143.9826278186629\n",
      "epoch  339  loss =  143.97981781007664\n",
      "epoch  340  loss =  143.97702419689242\n",
      "epoch  341  loss =  143.97424683684113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  342  loss =  143.97148558928603\n",
      "epoch  343  loss =  143.96874031519906\n",
      "epoch  344  loss =  143.9660108771383\n",
      "epoch  345  loss =  143.96329713922523\n",
      "epoch  346  loss =  143.9605989671228\n",
      "epoch  347  loss =  143.95791622801377\n",
      "epoch  348  loss =  143.95524879057976\n",
      "epoch  349  loss =  143.95259652497947\n",
      "epoch  350  loss =  143.9499593028288\n",
      "epoch  351  loss =  143.94733699718046\n",
      "epoch  352  loss =  143.94472948250367\n",
      "epoch  353  loss =  143.9421366346648\n",
      "epoch  354  loss =  143.93955833090826\n",
      "epoch  355  loss =  143.9369944498373\n",
      "epoch  356  loss =  143.9344448713954\n",
      "epoch  357  loss =  143.9319094768479\n",
      "epoch  358  loss =  143.92938814876413\n",
      "epoch  359  loss =  143.92688077099933\n",
      "epoch  360  loss =  143.92438722867763\n",
      "epoch  361  loss =  143.92190740817432\n",
      "epoch  362  loss =  143.91944119709945\n",
      "epoch  363  loss =  143.91698848428092\n",
      "epoch  364  loss =  143.9145491597482\n",
      "epoch  365  loss =  143.91212311471602\n",
      "epoch  366  loss =  143.90971024156883\n",
      "epoch  367  loss =  143.907310433845\n",
      "epoch  368  loss =  143.90492358622163\n",
      "epoch  369  loss =  143.90254959449928\n",
      "epoch  370  loss =  143.90018835558712\n",
      "epoch  371  loss =  143.8978397674884\n",
      "epoch  372  loss =  143.89550372928605\n",
      "epoch  373  loss =  143.89318014112823\n",
      "epoch  374  loss =  143.89086890421467\n",
      "epoch  375  loss =  143.88856992078317\n",
      "epoch  376  loss =  143.88628309409512\n",
      "epoch  377  loss =  143.88400832842348\n",
      "epoch  378  loss =  143.88174552903845\n",
      "epoch  379  loss =  143.87949460219545\n",
      "epoch  380  loss =  143.87725545512197\n",
      "epoch  381  loss =  143.87502799600523\n",
      "epoch  382  loss =  143.87281213397966\n",
      "epoch  383  loss =  143.8706077791152\n",
      "epoch  384  loss =  143.86841484240475\n",
      "epoch  385  loss =  143.8662332357528\n",
      "epoch  386  loss =  143.86406287196394\n",
      "epoch  387  loss =  143.8619036647309\n",
      "epoch  388  loss =  143.85975552862413\n",
      "epoch  389  loss =  143.85761837907992\n",
      "epoch  390  loss =  143.8554921323902\n",
      "epoch  391  loss =  143.85337670569115\n",
      "epoch  392  loss =  143.85127201695306\n",
      "epoch  393  loss =  143.84917798496974\n",
      "epoch  394  loss =  143.84709452934842\n",
      "epoch  395  loss =  143.84502157049943\n",
      "epoch  396  loss =  143.84295902962612\n",
      "epoch  397  loss =  143.8409068287158\n",
      "epoch  398  loss =  143.83886489052887\n",
      "epoch  399  loss =  143.83683313859044\n",
      "epoch  400  loss =  143.83481149718008\n",
      "epoch  401  loss =  143.83279989132316\n",
      "epoch  402  loss =  143.83079824678137\n",
      "epoch  403  loss =  143.82880649004406\n",
      "epoch  404  loss =  143.82682454831885\n",
      "epoch  405  loss =  143.8248523495236\n",
      "epoch  406  loss =  143.82288982227738\n",
      "epoch  407  loss =  143.82093689589178\n",
      "epoch  408  loss =  143.81899350036335\n",
      "epoch  409  loss =  143.8170595663645\n",
      "epoch  410  loss =  143.81513502523595\n",
      "epoch  411  loss =  143.8132198089785\n",
      "epoch  412  loss =  143.81131385024509\n",
      "epoch  413  loss =  143.80941708233328\n",
      "epoch  414  loss =  143.80752943917742\n",
      "epoch  415  loss =  143.8056508553411\n",
      "epoch  416  loss =  143.80378126600968\n",
      "epoch  417  loss =  143.80192060698297\n",
      "epoch  418  loss =  143.800068814668\n",
      "epoch  419  loss =  143.7982258260723\n",
      "epoch  420  loss =  143.79639157879575\n",
      "epoch  421  loss =  143.79456601102498\n",
      "epoch  422  loss =  143.79274906152554\n",
      "epoch  423  loss =  143.79094066963586\n",
      "epoch  424  loss =  143.78914077525982\n",
      "epoch  425  loss =  143.78734931886095\n",
      "epoch  426  loss =  143.78556624145565\n",
      "epoch  427  loss =  143.78379148460664\n",
      "epoch  428  loss =  143.782024990417\n",
      "epoch  429  loss =  143.78026670152366\n",
      "epoch  430  loss =  143.77851656109144\n",
      "epoch  431  loss =  143.77677451280718\n",
      "epoch  432  loss =  143.7750405008733\n",
      "epoch  433  loss =  143.7733144700024\n",
      "epoch  434  loss =  143.77159636541137\n",
      "epoch  435  loss =  143.76988613281546\n",
      "epoch  436  loss =  143.7681837184227\n",
      "epoch  437  loss =  143.76648906892868\n",
      "epoch  438  loss =  143.7648021315106\n",
      "epoch  439  loss =  143.76312285382215\n",
      "epoch  440  loss =  143.76145118398807\n",
      "epoch  441  loss =  143.75978707059883\n",
      "epoch  442  loss =  143.75813046270574\n",
      "epoch  443  loss =  143.75648130981494\n",
      "epoch  444  loss =  143.7548395618838\n",
      "epoch  445  loss =  143.75320516931455\n",
      "epoch  446  loss =  143.75157808295003\n",
      "epoch  447  loss =  143.7499582540688\n",
      "epoch  448  loss =  143.74834563438012\n",
      "epoch  449  loss =  143.74674017601942\n",
      "epoch  450  loss =  143.74514183154332\n",
      "epoch  451  loss =  143.74355055392573\n",
      "epoch  452  loss =  143.74196629655214\n",
      "epoch  453  loss =  143.74038901321643\n",
      "epoch  454  loss =  143.73881865811526\n",
      "epoch  455  loss =  143.7372551858447\n",
      "epoch  456  loss =  143.73569855139513\n",
      "epoch  457  loss =  143.73414871014737\n",
      "epoch  458  loss =  143.73260561786833\n",
      "epoch  459  loss =  143.73106923070722\n",
      "epoch  460  loss =  143.72953950519044\n",
      "epoch  461  loss =  143.72801639821927\n",
      "epoch  462  loss =  143.72649986706378\n",
      "epoch  463  loss =  143.72498986936066\n",
      "epoch  464  loss =  143.72348636310818\n",
      "epoch  465  loss =  143.72198930666312\n",
      "epoch  466  loss =  143.72049865873632\n",
      "epoch  467  loss =  143.71901437838946\n",
      "epoch  468  loss =  143.71753642503094\n",
      "epoch  469  loss =  143.7160647584124\n",
      "epoch  470  loss =  143.71459933862528\n",
      "epoch  471  loss =  143.71314012609707\n",
      "epoch  472  loss =  143.71168708158757\n",
      "epoch  473  loss =  143.71024016618614\n",
      "epoch  474  loss =  143.70879934130718\n",
      "epoch  475  loss =  143.70736456868784\n",
      "epoch  476  loss =  143.70593581038398\n",
      "epoch  477  loss =  143.70451302876708\n",
      "epoch  478  loss =  143.703096186521\n",
      "epoch  479  loss =  143.7016852466387\n",
      "epoch  480  loss =  143.700280172419\n",
      "epoch  481  loss =  143.69888092746362\n",
      "epoch  482  loss =  143.69748747567382\n",
      "epoch  483  loss =  143.69609978124754\n",
      "epoch  484  loss =  143.69471780867642\n",
      "epoch  485  loss =  143.69334152274243\n",
      "epoch  486  loss =  143.69197088851547\n",
      "epoch  487  loss =  143.69060587134985\n",
      "epoch  488  loss =  143.68924643688172\n",
      "epoch  489  loss =  143.6878925510265\n",
      "epoch  490  loss =  143.68654417997544\n",
      "epoch  491  loss =  143.68520129019322\n",
      "epoch  492  loss =  143.68386384841534\n",
      "epoch  493  loss =  143.68253182164474\n",
      "epoch  494  loss =  143.68120517715016\n",
      "epoch  495  loss =  143.67988388246246\n",
      "epoch  496  loss =  143.67856790537257\n",
      "epoch  497  loss =  143.6772572139288\n",
      "epoch  498  loss =  143.67595177643423\n",
      "epoch  499  loss =  143.6746515614443\n",
      "epoch  500  loss =  143.67335653776408\n",
      "epoch  501  loss =  143.6720666744459\n",
      "epoch  502  loss =  143.67078194078718\n",
      "epoch  503  loss =  143.66950230632747\n",
      "epoch  504  loss =  143.66822774084673\n",
      "epoch  505  loss =  143.6669582143624\n",
      "epoch  506  loss =  143.66569369712735\n",
      "epoch  507  loss =  143.66443415962763\n",
      "epoch  508  loss =  143.6631795725799\n",
      "epoch  509  loss =  143.66192990692957\n",
      "epoch  510  loss =  143.66068513384838\n",
      "epoch  511  loss =  143.65944522473217\n",
      "epoch  512  loss =  143.65821015119874\n",
      "epoch  513  loss =  143.65697988508583\n",
      "epoch  514  loss =  143.6557543984488\n",
      "epoch  515  loss =  143.6545336635587\n",
      "epoch  516  loss =  143.6533176529001\n",
      "epoch  517  loss =  143.6521063391691\n",
      "epoch  518  loss =  143.65089969527122\n",
      "epoch  519  loss =  143.6496976943196\n",
      "epoch  520  loss =  143.6485003096328\n",
      "epoch  521  loss =  143.6473075147329\n",
      "epoch  522  loss =  143.64611928334364\n",
      "epoch  523  loss =  143.64493558938852\n",
      "epoch  524  loss =  143.6437564069888\n",
      "epoch  525  loss =  143.64258171046166\n",
      "epoch  526  loss =  143.64141147431852\n",
      "epoch  527  loss =  143.6402456732629\n",
      "epoch  528  loss =  143.63908428218895\n",
      "epoch  529  loss =  143.63792727617937\n",
      "epoch  530  loss =  143.63677463050388\n",
      "epoch  531  loss =  143.63562632061743\n",
      "epoch  532  loss =  143.63448232215836\n",
      "epoch  533  loss =  143.63334261094658\n",
      "epoch  534  loss =  143.6322071629823\n",
      "epoch  535  loss =  143.6310759544441\n",
      "epoch  536  loss =  143.62994896168715\n",
      "epoch  537  loss =  143.6288261612419\n",
      "epoch  538  loss =  143.62770752981223\n",
      "epoch  539  loss =  143.62659304427365\n",
      "epoch  540  loss =  143.6254826816726\n",
      "epoch  541  loss =  143.6243764192236\n",
      "epoch  542  loss =  143.62327423430887\n",
      "epoch  543  loss =  143.62217610447607\n",
      "epoch  544  loss =  143.62108200743697\n",
      "epoch  545  loss =  143.61999192106626\n",
      "epoch  546  loss =  143.61890582339979\n",
      "epoch  547  loss =  143.61782369263284\n",
      "epoch  548  loss =  143.61674550711936\n",
      "epoch  549  loss =  143.61567124536992\n",
      "epoch  550  loss =  143.6146008860507\n",
      "epoch  551  loss =  143.61353440798175\n",
      "epoch  552  loss =  143.61247179013597\n",
      "epoch  553  loss =  143.61141301163735\n",
      "epoch  554  loss =  143.61035805176\n",
      "epoch  555  loss =  143.60930688992644\n",
      "epoch  556  loss =  143.60825950570674\n",
      "epoch  557  loss =  143.60721587881653\n",
      "epoch  558  loss =  143.60617598911645\n",
      "epoch  559  loss =  143.60513981661032\n",
      "epoch  560  loss =  143.60410734144418\n",
      "epoch  561  loss =  143.6030785439047\n",
      "epoch  562  loss =  143.60205340441848\n",
      "epoch  563  loss =  143.6010319035501\n",
      "epoch  564  loss =  143.6000140220017\n",
      "epoch  565  loss =  143.598999740611\n",
      "epoch  566  loss =  143.59798904035085\n",
      "epoch  567  loss =  143.59698190232726\n",
      "epoch  568  loss =  143.59597830777886\n",
      "epoch  569  loss =  143.5949782380756\n",
      "epoch  570  loss =  143.5939816747175\n",
      "epoch  571  loss =  143.59298859933332\n",
      "epoch  572  loss =  143.59199899368005\n",
      "epoch  573  loss =  143.59101283964114\n",
      "epoch  574  loss =  143.59003011922584\n",
      "epoch  575  loss =  143.58905081456788\n",
      "epoch  576  loss =  143.5880749079246\n",
      "epoch  577  loss =  143.58710238167552\n",
      "epoch  578  loss =  143.58613321832198\n",
      "epoch  579  loss =  143.58516740048503\n",
      "epoch  580  loss =  143.58420491090556\n",
      "epoch  581  loss =  143.58324573244272\n",
      "epoch  582  loss =  143.58228984807246\n",
      "epoch  583  loss =  143.58133724088748\n",
      "epoch  584  loss =  143.5803878940956\n",
      "epoch  585  loss =  143.57944179101904\n",
      "epoch  586  loss =  143.57849891509318\n",
      "epoch  587  loss =  143.57755924986566\n",
      "epoch  588  loss =  143.57662277899615\n",
      "epoch  589  loss =  143.57568948625405\n",
      "epoch  590  loss =  143.57475935551906\n",
      "epoch  591  loss =  143.5738323707789\n",
      "epoch  592  loss =  143.57290851612922\n",
      "epoch  593  loss =  143.57198777577273\n",
      "epoch  594  loss =  143.5710701340178\n",
      "epoch  595  loss =  143.5701555752778\n",
      "epoch  596  loss =  143.56924408407053\n",
      "epoch  597  loss =  143.56833564501687\n",
      "epoch  598  loss =  143.56743024284032\n",
      "epoch  599  loss =  143.56652786236575\n",
      "epoch  600  loss =  143.56562848851908\n",
      "epoch  601  loss =  143.56473210632566\n",
      "epoch  602  loss =  143.56383870091062\n",
      "epoch  603  loss =  143.56294825749674\n",
      "epoch  604  loss =  143.56206076140472\n",
      "epoch  605  loss =  143.56117619805147\n",
      "epoch  606  loss =  143.5602945529503\n",
      "epoch  607  loss =  143.55941581170916\n",
      "epoch  608  loss =  143.5585399600306\n",
      "epoch  609  loss =  143.55766698371048\n",
      "epoch  610  loss =  143.55679686863766\n",
      "epoch  611  loss =  143.55592960079304\n",
      "epoch  612  loss =  143.55506516624845\n",
      "epoch  613  loss =  143.55420355116655\n",
      "epoch  614  loss =  143.55334474179986\n",
      "epoch  615  loss =  143.55248872448973\n",
      "epoch  616  loss =  143.55163548566617\n",
      "epoch  617  loss =  143.55078501184644\n",
      "epoch  618  loss =  143.54993728963512\n",
      "epoch  619  loss =  143.54909230572284\n",
      "epoch  620  loss =  143.54825004688573\n",
      "epoch  621  loss =  143.54741049998498\n",
      "epoch  622  loss =  143.54657365196573\n",
      "epoch  623  loss =  143.54573948985697\n",
      "epoch  624  loss =  143.5449080007702\n",
      "epoch  625  loss =  143.5440791718992\n",
      "epoch  626  loss =  143.5432529905194\n",
      "epoch  627  loss =  143.542429443987\n",
      "epoch  628  loss =  143.5416085197385\n",
      "epoch  629  loss =  143.54079020529002\n",
      "epoch  630  loss =  143.53997448823668\n",
      "epoch  631  loss =  143.5391613562519\n",
      "epoch  632  loss =  143.53835079708696\n",
      "epoch  633  loss =  143.5375427985701\n",
      "epoch  634  loss =  143.53673734860624\n",
      "epoch  635  loss =  143.5359344351762\n",
      "epoch  636  loss =  143.53513404633605\n",
      "epoch  637  loss =  143.5343361702167\n",
      "epoch  638  loss =  143.53354079502333\n",
      "epoch  639  loss =  143.53274790903444\n",
      "epoch  640  loss =  143.5319575006017\n",
      "epoch  641  loss =  143.53116955814917\n",
      "epoch  642  loss =  143.53038407017308\n",
      "epoch  643  loss =  143.52960102524034\n",
      "epoch  644  loss =  143.52882041198947\n",
      "epoch  645  loss =  143.52804221912862\n",
      "epoch  646  loss =  143.52726643543588\n",
      "epoch  647  loss =  143.52649304975827\n",
      "epoch  648  loss =  143.52572205101185\n",
      "epoch  649  loss =  143.52495342818037\n",
      "epoch  650  loss =  143.52418717031532\n",
      "epoch  651  loss =  143.52342326653545\n",
      "epoch  652  loss =  143.5226617060256\n",
      "epoch  653  loss =  143.52190247803708\n",
      "epoch  654  loss =  143.52114557188656\n",
      "epoch  655  loss =  143.52039097695578\n",
      "epoch  656  loss =  143.51963868269098\n",
      "epoch  657  loss =  143.51888867860248\n",
      "epoch  658  loss =  143.51814095426425\n",
      "epoch  659  loss =  143.51739549931332\n",
      "epoch  660  loss =  143.51665230344923\n",
      "epoch  661  loss =  143.5159113564339\n",
      "epoch  662  loss =  143.51517264809064\n",
      "epoch  663  loss =  143.51443616830417\n",
      "epoch  664  loss =  143.5137019070199\n",
      "epoch  665  loss =  143.51296985424366\n",
      "epoch  666  loss =  143.512240000041\n",
      "epoch  667  loss =  143.51151233453683\n",
      "epoch  668  loss =  143.51078684791526\n",
      "epoch  669  loss =  143.5100635304186\n",
      "epoch  670  loss =  143.5093423723476\n",
      "epoch  671  loss =  143.5086233640603\n",
      "epoch  672  loss =  143.50790649597232\n",
      "epoch  673  loss =  143.50719175855585\n",
      "epoch  674  loss =  143.50647914233969\n",
      "epoch  675  loss =  143.50576863790826\n",
      "epoch  676  loss =  143.50506023590182\n",
      "epoch  677  loss =  143.50435392701584\n",
      "epoch  678  loss =  143.50364970200022\n",
      "epoch  679  loss =  143.5029475516596\n",
      "epoch  680  loss =  143.50224746685217\n",
      "epoch  681  loss =  143.50154943848992\n",
      "epoch  682  loss =  143.50085345753808\n",
      "epoch  683  loss =  143.5001595150143\n",
      "epoch  684  loss =  143.49946760198907\n",
      "epoch  685  loss =  143.4987777095845\n",
      "epoch  686  loss =  143.49808982897446\n",
      "epoch  687  loss =  143.49740395138426\n",
      "epoch  688  loss =  143.49672006808996\n",
      "epoch  689  loss =  143.49603817041782\n",
      "epoch  690  loss =  143.49535824974492\n",
      "epoch  691  loss =  143.4946802974976\n",
      "epoch  692  loss =  143.4940043051518\n",
      "epoch  693  loss =  143.49333026423253\n",
      "epoch  694  loss =  143.4926581663136\n",
      "epoch  695  loss =  143.491988003017\n",
      "epoch  696  loss =  143.4913197660131\n",
      "epoch  697  loss =  143.4906534470195\n",
      "epoch  698  loss =  143.48998903780162\n",
      "epoch  699  loss =  143.4893265301715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  700  loss =  143.48866591598807\n",
      "epoch  701  loss =  143.48800718715657\n",
      "epoch  702  loss =  143.48735033562812\n",
      "epoch  703  loss =  143.48669535339977\n",
      "epoch  704  loss =  143.48604223251377\n",
      "epoch  705  loss =  143.4853909650574\n",
      "epoch  706  loss =  143.48474154316284\n",
      "epoch  707  loss =  143.48409395900646\n",
      "epoch  708  loss =  143.4834482048087\n",
      "epoch  709  loss =  143.48280427283422\n",
      "epoch  710  loss =  143.48216215539068\n",
      "epoch  711  loss =  143.4815218448291\n",
      "epoch  712  loss =  143.4808833335435\n",
      "epoch  713  loss =  143.48024661397014\n",
      "epoch  714  loss =  143.4796116785879\n",
      "epoch  715  loss =  143.47897851991752\n",
      "epoch  716  loss =  143.47834713052137\n",
      "epoch  717  loss =  143.47771750300336\n",
      "epoch  718  loss =  143.47708963000832\n",
      "epoch  719  loss =  143.47646350422215\n",
      "epoch  720  loss =  143.47583911837097\n",
      "epoch  721  loss =  143.47521646522168\n",
      "epoch  722  loss =  143.47459553758048\n",
      "epoch  723  loss =  143.47397632829393\n",
      "epoch  724  loss =  143.4733588302477\n",
      "epoch  725  loss =  143.47274303636664\n",
      "epoch  726  loss =  143.47212893961446\n",
      "epoch  727  loss =  143.4715165329938\n",
      "epoch  728  loss =  143.47090580954534\n",
      "epoch  729  loss =  143.47029676234808\n",
      "epoch  730  loss =  143.4696893845187\n",
      "epoch  731  loss =  143.46908366921141\n",
      "epoch  732  loss =  143.4684796096181\n",
      "epoch  733  loss =  143.46787719896753\n",
      "epoch  734  loss =  143.46727643052515\n",
      "epoch  735  loss =  143.4666772975931\n",
      "epoch  736  loss =  143.46607979351003\n",
      "epoch  737  loss =  143.46548391165035\n",
      "epoch  738  loss =  143.4648896454245\n",
      "epoch  739  loss =  143.46429698827868\n",
      "epoch  740  loss =  143.46370593369403\n",
      "epoch  741  loss =  143.46311647518723\n",
      "epoch  742  loss =  143.46252860630943\n",
      "epoch  743  loss =  143.4619423206468\n",
      "epoch  744  loss =  143.46135761181984\n",
      "epoch  745  loss =  143.46077447348316\n",
      "epoch  746  loss =  143.46019289932522\n",
      "epoch  747  loss =  143.45961288306844\n",
      "epoch  748  loss =  143.45903441846863\n",
      "epoch  749  loss =  143.45845749931507\n",
      "epoch  750  loss =  143.45788211942977\n",
      "epoch  751  loss =  143.45730827266777\n",
      "epoch  752  loss =  143.45673595291686\n",
      "epoch  753  loss =  143.45616515409694\n",
      "epoch  754  loss =  143.45559587016047\n",
      "epoch  755  loss =  143.4550280950915\n",
      "epoch  756  loss =  143.45446182290624\n",
      "epoch  757  loss =  143.45389704765213\n",
      "epoch  758  loss =  143.4533337634083\n",
      "epoch  759  loss =  143.4527719642846\n",
      "epoch  760  loss =  143.45221164442225\n",
      "epoch  761  loss =  143.451652797993\n",
      "epoch  762  loss =  143.45109541919925\n",
      "epoch  763  loss =  143.45053950227353\n",
      "epoch  764  loss =  143.44998504147873\n",
      "epoch  765  loss =  143.44943203110765\n",
      "epoch  766  loss =  143.44888046548277\n",
      "epoch  767  loss =  143.44833033895617\n",
      "epoch  768  loss =  143.44778164590923\n",
      "epoch  769  loss =  143.44723438075263\n",
      "epoch  770  loss =  143.44668853792612\n",
      "epoch  771  loss =  143.44614411189795\n",
      "epoch  772  loss =  143.4456010971651\n",
      "epoch  773  loss =  143.44505948825318\n",
      "epoch  774  loss =  143.44451927971582\n",
      "epoch  775  loss =  143.44398046613478\n",
      "epoch  776  loss =  143.4434430421198\n",
      "epoch  777  loss =  143.44290700230815\n",
      "epoch  778  loss =  143.44237234136477\n",
      "epoch  779  loss =  143.44183905398194\n",
      "epoch  780  loss =  143.44130713487897\n",
      "epoch  781  loss =  143.4407765788024\n",
      "epoch  782  loss =  143.44024738052545\n",
      "epoch  783  loss =  143.43971953484802\n",
      "epoch  784  loss =  143.43919303659658\n",
      "epoch  785  loss =  143.43866788062377\n",
      "epoch  786  loss =  143.43814406180857\n",
      "epoch  787  loss =  143.43762157505586\n",
      "epoch  788  loss =  143.43710041529621\n",
      "epoch  789  loss =  143.4365805774861\n",
      "epoch  790  loss =  143.43606205660745\n",
      "epoch  791  loss =  143.43554484766744\n",
      "epoch  792  loss =  143.4350289456984\n",
      "epoch  793  loss =  143.4345143457577\n",
      "epoch  794  loss =  143.4340010429277\n",
      "epoch  795  loss =  143.4334890323154\n",
      "epoch  796  loss =  143.43297830905232\n",
      "epoch  797  loss =  143.4324688682944\n",
      "epoch  798  loss =  143.43196070522177\n",
      "epoch  799  loss =  143.4314538150387\n",
      "epoch  800  loss =  143.43094819297355\n",
      "epoch  801  loss =  143.4304438342782\n",
      "epoch  802  loss =  143.4299407342285\n",
      "epoch  803  loss =  143.42943888812343\n",
      "epoch  804  loss =  143.42893829128562\n",
      "epoch  805  loss =  143.42843893906075\n",
      "epoch  806  loss =  143.42794082681775\n",
      "epoch  807  loss =  143.42744394994833\n",
      "epoch  808  loss =  143.42694830386682\n",
      "epoch  809  loss =  143.4264538840106\n",
      "epoch  810  loss =  143.4259606858393\n",
      "epoch  811  loss =  143.4254687048349\n",
      "epoch  812  loss =  143.42497793650168\n",
      "epoch  813  loss =  143.42448837636593\n",
      "epoch  814  loss =  143.424000019976\n",
      "epoch  815  loss =  143.42351286290207\n",
      "epoch  816  loss =  143.42302690073598\n",
      "epoch  817  loss =  143.4225421290909\n",
      "epoch  818  loss =  143.42205854360188\n",
      "epoch  819  loss =  143.42157613992492\n",
      "epoch  820  loss =  143.42109491373714\n",
      "epoch  821  loss =  143.42061486073703\n",
      "epoch  822  loss =  143.42013597664376\n",
      "epoch  823  loss =  143.41965825719714\n",
      "epoch  824  loss =  143.41918169815793\n",
      "epoch  825  loss =  143.41870629530732\n",
      "epoch  826  loss =  143.41823204444685\n",
      "epoch  827  loss =  143.41775894139832\n",
      "epoch  828  loss =  143.4172869820039\n",
      "epoch  829  loss =  143.41681616212549\n",
      "epoch  830  loss =  143.41634647764516\n",
      "epoch  831  loss =  143.41587792446452\n",
      "epoch  832  loss =  143.41541049850525\n",
      "epoch  833  loss =  143.4149441957083\n",
      "epoch  834  loss =  143.41447901203404\n",
      "epoch  835  loss =  143.4140149434624\n",
      "epoch  836  loss =  143.41355198599226\n",
      "epoch  837  loss =  143.41309013564188\n",
      "epoch  838  loss =  143.41262938844832\n",
      "epoch  839  loss =  143.4121697404674\n",
      "epoch  840  loss =  143.41171118777396\n",
      "epoch  841  loss =  143.4112537264614\n",
      "epoch  842  loss =  143.41079735264162\n",
      "epoch  843  loss =  143.41034206244498\n",
      "epoch  844  loss =  143.4098878520202\n",
      "epoch  845  loss =  143.40943471753397\n",
      "epoch  846  loss =  143.40898265517143\n",
      "epoch  847  loss =  143.40853166113558\n",
      "epoch  848  loss =  143.40808173164723\n",
      "epoch  849  loss =  143.4076328629451\n",
      "epoch  850  loss =  143.40718505128547\n",
      "epoch  851  loss =  143.40673829294238\n",
      "epoch  852  loss =  143.4062925842071\n",
      "epoch  853  loss =  143.40584792138856\n",
      "epoch  854  loss =  143.40540430081268\n",
      "epoch  855  loss =  143.40496171882273\n",
      "epoch  856  loss =  143.40452017177896\n",
      "epoch  857  loss =  143.40407965605874\n",
      "epoch  858  loss =  143.40364016805606\n",
      "epoch  859  loss =  143.4032017041819\n",
      "epoch  860  loss =  143.40276426086402\n",
      "epoch  861  loss =  143.40232783454627\n",
      "epoch  862  loss =  143.40189242168955\n",
      "epoch  863  loss =  143.4014580187708\n",
      "epoch  864  loss =  143.40102462228342\n",
      "epoch  865  loss =  143.4005922287369\n",
      "epoch  866  loss =  143.400160834657\n",
      "epoch  867  loss =  143.39973043658526\n",
      "epoch  868  loss =  143.39930103107926\n",
      "epoch  869  loss =  143.3988726147125\n",
      "epoch  870  loss =  143.39844518407415\n",
      "epoch  871  loss =  143.398018735769\n",
      "epoch  872  loss =  143.39759326641735\n",
      "epoch  873  loss =  143.3971687726552\n",
      "epoch  874  loss =  143.3967452511336\n",
      "epoch  875  loss =  143.39632269851927\n",
      "epoch  876  loss =  143.39590111149377\n",
      "epoch  877  loss =  143.39548048675397\n",
      "epoch  878  loss =  143.3950608210119\n",
      "epoch  879  loss =  143.39464211099437\n",
      "epoch  880  loss =  143.39422435344292\n",
      "epoch  881  loss =  143.39380754511416\n",
      "epoch  882  loss =  143.3933916827793\n",
      "epoch  883  loss =  143.39297676322408\n",
      "epoch  884  loss =  143.39256278324896\n",
      "epoch  885  loss =  143.3921497396686\n",
      "epoch  886  loss =  143.3917376293122\n",
      "epoch  887  loss =  143.39132644902315\n",
      "epoch  888  loss =  143.3909161956591\n",
      "epoch  889  loss =  143.39050686609198\n",
      "epoch  890  loss =  143.39009845720742\n",
      "epoch  891  loss =  143.3896909659055\n",
      "epoch  892  loss =  143.38928438909946\n",
      "epoch  893  loss =  143.38887872371717\n",
      "epoch  894  loss =  143.38847396669973\n",
      "epoch  895  loss =  143.38807011500214\n",
      "epoch  896  loss =  143.38766716559283\n",
      "epoch  897  loss =  143.38726511545366\n",
      "epoch  898  loss =  143.38686396158036\n",
      "epoch  899  loss =  143.38646370098144\n",
      "epoch  900  loss =  143.3860643306791\n",
      "epoch  901  loss =  143.38566584770857\n",
      "epoch  902  loss =  143.3852682491184\n",
      "epoch  903  loss =  143.38487153196982\n",
      "epoch  904  loss =  143.38447569333758\n",
      "epoch  905  loss =  143.38408073030897\n",
      "epoch  906  loss =  143.38368663998423\n",
      "epoch  907  loss =  143.3832934194764\n",
      "epoch  908  loss =  143.3829010659112\n",
      "epoch  909  loss =  143.38250957642714\n",
      "epoch  910  loss =  143.38211894817508\n",
      "epoch  911  loss =  143.38172917831835\n",
      "epoch  912  loss =  143.38134026403307\n",
      "epoch  913  loss =  143.38095220250733\n",
      "epoch  914  loss =  143.38056499094174\n",
      "epoch  915  loss =  143.38017862654905\n",
      "epoch  916  loss =  143.37979310655427\n",
      "epoch  917  loss =  143.37940842819435\n",
      "epoch  918  loss =  143.3790245887185\n",
      "epoch  919  loss =  143.37864158538758\n",
      "epoch  920  loss =  143.37825941547464\n",
      "epoch  921  loss =  143.37787807626452\n",
      "epoch  922  loss =  143.37749756505366\n",
      "epoch  923  loss =  143.37711787915032\n",
      "epoch  924  loss =  143.37673901587448\n",
      "epoch  925  loss =  143.37636097255762\n",
      "epoch  926  loss =  143.3759837465426\n",
      "epoch  927  loss =  143.3756073351841\n",
      "epoch  928  loss =  143.37523173584782\n",
      "epoch  929  loss =  143.3748569459111\n",
      "epoch  930  loss =  143.37448296276233\n",
      "epoch  931  loss =  143.37410978380115\n",
      "epoch  932  loss =  143.37373740643864\n",
      "epoch  933  loss =  143.3733658280964\n",
      "epoch  934  loss =  143.3729950462077\n",
      "epoch  935  loss =  143.37262505821616\n",
      "epoch  936  loss =  143.37225586157695\n",
      "epoch  937  loss =  143.3718874537558\n",
      "epoch  938  loss =  143.37151983222896\n",
      "epoch  939  loss =  143.37115299448394\n",
      "epoch  940  loss =  143.3707869380186\n",
      "epoch  941  loss =  143.37042166034158\n",
      "epoch  942  loss =  143.37005715897192\n",
      "epoch  943  loss =  143.3696934314395\n",
      "epoch  944  loss =  143.36933047528433\n",
      "epoch  945  loss =  143.36896828805706\n",
      "epoch  946  loss =  143.36860686731842\n",
      "epoch  947  loss =  143.3682462106398\n",
      "epoch  948  loss =  143.3678863156025\n",
      "epoch  949  loss =  143.3675271797982\n",
      "epoch  950  loss =  143.36716880082878\n",
      "epoch  951  loss =  143.36681117630587\n",
      "epoch  952  loss =  143.36645430385155\n",
      "epoch  953  loss =  143.36609818109764\n",
      "epoch  954  loss =  143.36574280568576\n",
      "epoch  955  loss =  143.3653881752677\n",
      "epoch  956  loss =  143.36503428750498\n",
      "epoch  957  loss =  143.3646811400688\n",
      "epoch  958  loss =  143.36432873064012\n",
      "epoch  959  loss =  143.36397705690953\n",
      "epoch  960  loss =  143.3636261165773\n",
      "epoch  961  loss =  143.36327590735337\n",
      "epoch  962  loss =  143.36292642695696\n",
      "epoch  963  loss =  143.36257767311693\n",
      "epoch  964  loss =  143.3622296435714\n",
      "epoch  965  loss =  143.36188233606816\n",
      "epoch  966  loss =  143.36153574836405\n",
      "epoch  967  loss =  143.3611898782252\n",
      "epoch  968  loss =  143.3608447234271\n",
      "epoch  969  loss =  143.36050028175438\n",
      "epoch  970  loss =  143.36015655100067\n",
      "epoch  971  loss =  143.35981352896897\n",
      "epoch  972  loss =  143.3594712134711\n",
      "epoch  973  loss =  143.3591296023277\n",
      "epoch  974  loss =  143.35878869336892\n",
      "epoch  975  loss =  143.35844848443313\n",
      "epoch  976  loss =  143.3581089733681\n",
      "epoch  977  loss =  143.35777015803006\n",
      "epoch  978  loss =  143.35743203628425\n",
      "epoch  979  loss =  143.3570946060044\n",
      "epoch  980  loss =  143.35675786507326\n",
      "epoch  981  loss =  143.35642181138164\n",
      "epoch  982  loss =  143.35608644282962\n",
      "epoch  983  loss =  143.35575175732524\n",
      "epoch  984  loss =  143.35541775278543\n",
      "epoch  985  loss =  143.35508442713547\n",
      "epoch  986  loss =  143.35475177830887\n",
      "epoch  987  loss =  143.35441980424764\n",
      "epoch  988  loss =  143.35408850290233\n",
      "epoch  989  loss =  143.35375787223145\n",
      "epoch  990  loss =  143.35342791020184\n",
      "epoch  991  loss =  143.35309861478876\n",
      "epoch  992  loss =  143.3527699839754\n",
      "epoch  993  loss =  143.3524420157531\n",
      "epoch  994  loss =  143.35211470812132\n",
      "epoch  995  loss =  143.35178805908754\n",
      "epoch  996  loss =  143.35146206666738\n",
      "epoch  997  loss =  143.3511367288842\n",
      "epoch  998  loss =  143.35081204376945\n",
      "epoch  999  loss =  143.3504880093623\n",
      "['working', 'radicals', 'anarchism']\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\" \n",
    "corpus += \"anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans culottes of the french revolution\"\n",
    "epochs = 1000\n",
    "  \n",
    "training_data = preprocessing(corpus) \n",
    "w2v = word2vec() \n",
    "  \n",
    "prepare_data_for_training(training_data,w2v) \n",
    "w2v.train(epochs)  \n",
    "  \n",
    "print(w2v.predict(\"term\",3))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model Predicts 'anarchism', 'originated' and 'class' to have similar meaning to that of 'term' which is somewhat true.<br>\n",
    "Hence we can say that this model is Functional."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
